---
title: "Avond Sessie 04: Machine learning"
subtitle: "Inleiding R"
author: "Longhow Lam"
output:
  html_notebook:
    theme: sandstone
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
---


---

<br>


```{r, eval=FALSE, include=FALSE}
library(rpart)
library(glmnet)
library(ranger)
library(xgboost)
library(ROCR)
library(titanic)
library(rattle)
library(mlr)
library(dplyr)
```



# predictive modeling technieken

---

In R kan je veel verschillende predictive modellen fitten. We behandelen alleen een paar in deze sessie. 
Lineare regressie `lm`, logistische regressie met `glm`, decision trees, `rpart` en ensemble van trees met `ranger` en  `xgboost`. Ik zal deze functies apart behandelen maar we zullen later in de sessie zien met het package `mlr` hoe je op een meer unforme manier meerdere modellen kan proberen op een data set.


## lineare regressie 

We beginnen met lineare regressie. Modellen waar de Target variable continu (numeric) is. We nemen als voorbeeld de data in mtcars.

```{r}
mtcars
modelout = lm(  hp ~ wt    , data = mtcars)
modelout2 = lm( hp ~ wt + mpg, data = mtcars) 

modelout
```

Modeling functies in R retourneren vaan objecten met van alles er nog wat in. De functie `lm` levert een object af van de klasse lm.

```{r}
class(modelout)
names(modelout)
modelout$coefficients

summary(modelout)
plot(modelout)
```

### formula objects

```{r}
names(mtcars)

f1 <- hp ~ wt + carb + vs
m1 = lm(f1, data = mtcars)

f2 <- hp ~ carb*wt*vs
m2 = lm(f2, data = mtcars)

f2a <- hp ~ I(carb*wt*vs)
m2a = lm(f2a, data = mtcars)

f3 <- hp ~ carb*wt*vs - carb:wt:vs
m3 = lm(f3, data = mtcars)

f4 = hp ~ .
m4 = lm(f4, data = mtcars)

## vergelijken van verschillende modellen
anova(m1,m3,m2)
```


## Splitsen in train en test

Het is gebruikelijk om een data set random te splitsen in een train en test set. Op de train set wordt een predictive model getraind. En het model dat we getraind hebben testen we op de test set.

We gebruiken hier een copy van de titanic set omdat we de data iets wijzigen.

```{r}
perc = 0.80

## maak een categorische kolom van survived
myTitan = titanic::titanic_train
myTitan %>% mutate(
  Survived = ifelse(Survived < 1, "N", "Y") %>% as.factor
)

table(myTitan$Survived)

N = dim(myTitan)[1]

train = sample(1:N, size = floor(perc*N))

TTrain = myTitan[train,]
TTest = myTitan[-train,]


```


## logistic regression

Een logistic regression is een van de simpele predictive modellen om mee te beginnen als je classificatie wilt doen. we gaan uit van een binaire Target (Y /N). We gebruiken de `TTrain` data set om een model te fitten.

```{r}
out.glm = glm(Survived ~ Sex + Age +Pclass,  data = TTrain , family = binomial)
summary(out.glm)

```

## decision tree

Een decision tree genereert op basis van een algoritme regels die je kan gebruiken om te classificeren. 

```{r}
tree.out = rpart(Survived ~ Sex + Age +Pclass, data = TTrain)

plot(tree.out)
text(tree.out, use.n = TRUE)


fancyRpartPlot(tree.out)

### larger trees with complexity parameter
tree.out = rpart(Survived ~ Sex + Age +Pclass, data = titanic_train, control = list(cp=0.005))
fancyRpartPlot(tree.out)

```


## random forest met ranger

Ee random forest is een zogenaamde ensemble model. Het is de combinatie van (veel) verschillende bomen.

```{r}
ranger.out = ranger( Survived ~ Sex + Age + Pclass, data = TTrain)

### er zijn missende waarden. We zouden ze kunnen verwijdern
TTrain = TTrain %>% filter(!is.na(Age))
ranger.out = ranger( Survived ~ Sex + Age +Pclass, data = TTrain, importance = "impurity")

ranger.out

```

## xgboost

Extreme gradient boosting wordt de laatste tijd ook veel gebruikt in Kaggle competities. Zoals bij random forests is een xgboost model ook een ensemble van decision trees, maar de trees zijn nu niet onafhankelijk van elkaar.

Met de library `xgboost` kan je in R extreme gradient boosting modellen fitten. De aanroep is anders dan wat we tot nu toe gezien hebben. De `xgboost` functie moet een matrix met input variabelen worden meegegeven.

```{r}
Titan_Inputmatrix = sparse.model.matrix( Survived ~ Sex + Age +Pclass, data = TTrain)

xgboost.out = xgboost(Titan_Inputmatrix, label = TTrain$Survived, nrounds = 10)

## er zijn diverse opties mee te geven aan xgboost
param = list(
  objective = 'binary:logistic',
  eval_metric = 'auc'
)

xgboost.out = xgboost(params=param, Titan_Inputmatrix, label = TTrain$Survived, nrounds = 10)
```


## predictie en validatie

Met een test set kan je bepalen hoe goed een model is. Gebruik het model object van een modelfit om een test set te scoren en de scores met de ware uitkomsten te vergelijken.

### predicties

Voor binaire classificaties is het handig om response kansen uit te rekenen. Voor logistische regressie met `glm` gebeurt dit niet automatisch

```{r}
pred_GLM = predict(out.glm, data = TTest, type='response')
hist(pred_GLM)
```

Voorspelling van de decision tree, en random forest ranger.

```{r}
pred_tree = predict(tree.out, data = TTest)
hist(pred_tree)

TTest = TTest %>% filter(!is.na(Age))
pred_ranger = predict(ranger.out, data = TTest)
hist(pred_ranger$predictions)
```

En voor xgboost moet je ook de test set als matrix veranderen

```{r}
Titan_Testmatrix = sparse.model.matrix( Survived ~ Sex + Age +Pclass, data = TTest)
pred_xgboost = predict(xgboost.out, newdata = Titan_Testmatrix)
hist(pred_xgboost)
```




### Variable importance in trees

### roc curves and hit rates

````{r}
test 
testpr = predict(tree.out, titanic_test)
test$predictie = testpr


rocResultTEST = roc(Target  ~ predictionRANGER, data = test , auc=TRUE, ci =TRUE)
plot(rocResultTEST)


## HITRATES 
RANGER_test = test  %>% mutate(
  Target = ifelse(Target== "Y",1,0)
)

RANGER_test %>% 
  ggplot(aes(predictionRANGER, Target))  +
  geom_smooth() +
  geom_abline(slope = 1,intercept = 0) +
  ggtitle("Young class hit rate on test set") + scale_y_continuous(limits=c(0,1))

ggplot(data = RANGER_test, aes(predictionRANGER, fill = "test")) + geom_density(color='black') +
  ggtitle("Distribution of Young score (Probability that Age < 35)")

````




<br>

# The h2o package

---

H2O is een schaalbaar machine learning platform die je vanuit R kan bedienen, het bevat veel technieken en voor grotere sets waar gewoon R moeite mee heeft kan h2o een uitkomst bieden. H2o heeft een eigen 'executie engine' geschreven in java. Bij het opstarten van h2o vanuit R wordt dan ook een apart h2o process opgestart waar je data vanuit R naar toe moet uploaden.

```{r}
library(h2o)

# initialiseer h20 via R

h2o.init(nthreads=-1, port=54323, startH2O = FALSE)

### upload een R data set naar h2o: iris voorbeeldje
iris.h2o = as.h2o(iris)
titanic.h2o = as.h2o(titanic::titanic_train) 

### Je kan ook direct text files inlezen in h20 met 
h2o.importFile(path="C:\een file.txt", sep=",")

### welke files zijn er in h2o
h2o.ls()
```


Er zijn diverse modellen die je kan trainen, we zullen hier een tweetal laten zien, neural netwerks en random forests

```{r}
## model op titanic

## splits train en test

NNmodel = h2o.deeplearning(
  x = inp,
  y = "BAD",
  training_frame  = HMEQT,
  validation_frame = HMEQV,
  hidden = c(35,35),
  epochs = 250,
  variable_importances = TRUE
)

show(NNmodel)
h2o.varimp(NNmodel)

### Voorspel op validatie set en zet uit in roc curve
HMEQVP = h2o.predict(NNmodel, newdata = HMEQV)
head(HMEQVP)

NEURAL.PERF = as.data.frame(HMEQVP)

plot.roc(HMEQ_VALID$BAD, NEURAL.PERF$p1  , add=T, col="red")


### fit een random forest



```


<br>

# The mlr package

---

Met het `mlr` package kan je makkelijk verschillende modellen trainen en testen op een meer uniforme manier. In R hebben alle machine learning technieken net weer verschillende aanroepen en de uitkomst is vaak ook steeds anders. Met `mlr` kan je dit uniform stroomlijnen. Het maken van een predictive model (welk model dan ook)  bestaat altijd uit een aantal stappen. Deze zijn te beschrijven en uit te voeren in mlr.

We gebruiken de `titanic` data set als test in `mlr` en doorlopen een aantal stappen on een aantal modellen te benchmarken.

* neuraal netwerk,
* gradient boosting,
* random forest
* xgboost
* decision tree,
* logistic regression via glmnet



## specificeren van technieken en hun opties

```{r}
configureMlr(on.par.without.desc = "warn")

n.importance = 30
ptype = "prob"

N_CV_iter = 10

parameters_rf = list(
  num.trees  = 500
)

parameters_rpart = list(
  cp=0.0001
)

parameters_glmnet = list(
  alpha  = 1
)

parameters_NN = list(
  hidden = c(15,15)
)

parameters_xgboost = list(
  nrounds  = 5,
  max.depth = 7
)

```

Maak nu een Lijst van learners die je wilt testen

```{r}
RF_Learner = makeLearner(
  "classif.ranger",
  predict.type = ptype,
  par.vals = parameters_rf
)

xgboost_Learner = makeLearner(
  "classif.xgboost",
  predict.type = ptype,
  par.vals = parameters_xgboost
)

rpart_Learner = makeLearner(
  "classif.rpart",
  predict.type = ptype,
  par.vals = parameters_rpart
)

binomial_Learner = makeLearner(
  "classif.binomial",
  predict.type = ptype
)

glmnet_Learner = makeLearner(
  "classif.cvglmnet", 
  predict.type = ptype,
  par.vals = parameters_glmnet
)

h2ogbm_Learner = makeLearner(
  "classif.h2o.gbm", 
  predict.type = "prob"
)

h2oNN_Learner = makeLearner(
  "classif.h2o.deeplearning",
  predict.type = ptype,
  par.vals = parameters_NN
)


learners = list(
  rpart_Learner,
  RF_Learner,
  binomial_Learner,
  glmnet_Learner,
#  h2ogbm_Learner,
#  h2oNN_Learner,
  xgboost_Learner
)

```


Specificeer de data, de inputs en de target,  de classificatie of regressie task 

Wat wil je modelleren: Kans op level "Y", dan dien je positive = "Y" op te geven. Bij een binaie target met Y en N levels wordt namelijk standaard "N"gebruik (alfabetisch)

```{r}
classify.task = makeClassifTask(id = "RTL_NIEUWSAPP_AGE", data = ABT, target = "Target", positive = "Y")

## Overzicht van de taak en kolom informatie

print(classify.task)
getTaskDescription(classify.task)
summarizeColumns(classify.task)

```

variablen hard uitsluiten 

```{r}

#classify.task = dropFeatures(classify.task, vars.to.drop )

## Weghalen van (bijna) constante variabelen 

## Je kan ook 'bijna' constante variabelen weghalen: perc iets hoger zetten
## not done here
#classify.task = removeConstantFeatures(classify.task, perc = 0)

```

Zeldzame levels van factors samenvoegen. Het is gebruikelijk om zeldzame levels te verwijderen of te mergen

```{r}
#classify.task = mergeSmallFactorLevels (classify.task, min.perc = 0.02,  new.level = ".merged")
#summarizeColumns(classify.task)

```


```{r}
## Feature selection 

#fv = generateFilterValuesData(classify.task,  method = c("information.gain", "chi.squared", "rf.importance"))
fv = generateFilterValuesData(classify.task,  method = c("information.gain", "chi.squared"))


## display en plot importance

importance = fv$data %>% arrange(desc(information.gain))
head(importance, n = n.importance)
plotFilterValues(fv, n.show = 2*n.importance)

 
## no filtering
# summarizeColumns(filtered.task)
# getTaskNFeats(filtered.task)

```


## Sample schema 


uitleg.....

```{r}
#SampleStrageyHO = makeResampleDesc("Holdout", split=0.75)
# SampleStrageyCV = makeResampleDesc("CV", iters = N_CV_iter)
N = dim(ABT)[1]
SampleStrageyHO = makeFixedHoldoutInstance(tidx, testidx, N)
```

## uitvoeren machine learning becnhamrk 

```{r}
br1 = mlr::benchmark(learners, classify.task, SampleStrageyHO, measures = list(mlr::mmce, mlr::auc, mlr::f1))
br2 = mlr::benchmark(learners, filtered.task, SampleStrageyCV, measures = list(mlr::mmce, mlr::auc, mlr::f1))


## Vergelijking machine learning modellen

data.frame(br1) %>% arrange(desc(auc))
plotBMRSummary(br1, measure = mlr::auc)
plotBMRBoxplots(br2, measure = mlr::auc)


#### ROC curves
NModels = length(br1$results$RTL_NIEUWSAPP_AGE)
for(i in 1:NModels)
{
  tmp2  = br1$results$RTL_NIEUWSAPP_AGE[[i]]$pred$data
  rocResultTEST = roc(truth  ~ prob.Y, data = tmp2 )
  if(i==1)
  {
    plot(rocResultTEST, col=i)
  }else{
    plot(rocResultTEST, col=i, add=TRUE)
  }
}

legend( 0.6,0.6, names(br1$results$RTL_NIEUWSAPP_AGE), col=1:NModels,lwd=2)
title("RTL_NIEUWS_APP AGE MODEL")
```

<br>

# Unsupervised learning

---

De bovenstaande code was gericht op predictive modeling, ook wel supervised learning genoemd: met input variabelen een target variable proberen te voorspellen. In deze sectie zullen we een tweetal technieken laten zien waar geen target variabele is, ook wel unsupervised learning genoemd.

## k-means Clustering


```{r}
kmeans
```


## hierarchische clustering
```{r}
hclust
```


# Market basket analyse

Met market basket analyse (ook wel association rules mining) genoemd kan je uit "transacties van klanten" vaak voorkomende combinaties of juiste hele "sterke combinaties" van producten bepalen. Hieronder volgt een voorbeeldje.

```{r}
library(arules)
library(datasets)

data(Groceries)

rules <- apriori(Groceries, parameter = list(supp = 0.001, conf = 0.8))
rules = sort(rules, decreasing = TRUE, na.last = NA, by = "lift")
inspect(head(rules,n = 15))
```

De data `Groeceries` is al in een zogenaamde transactions object, vaak zul je deze data vanuit een transactionele data frame moeten converteren naar een transaction object.

```{r}
trxDF = readRDS("data/boodschappen.RDs")

Groceries2 = as(
  split(
    trxDF$item,
    trxDF$id
    ),
  "transactions"
)
Groceries2
rules2 <- apriori(Groceries2, parameter = list(supp = 0.001, conf = 0.8))
```


Nu je de regels hebt kan je filteren op regels. Welke regels bevatten bepaalde producten.

```{r}
rules.subset2 <- subset(rules, lhs %in% c("cereals", "curd"))
rules.subset2
inspect(head(rules.subset2,n=15))
```

Of als iemand een bepaalde reeks transacties heeft welke regels horen daar bij en welk product kan je dan aanraden.

```{r}
PersoonA = data.frame(
  id = rep(1,3),
  #item = c("butter","jam"),
  item2 = c("butter","curd","domestic eggs")
)

trxs_trans = as(
  split(
    PersoonA$item2,
    PersoonA$id
    ),
  "transactions"
)
inspect(trxs_trans)

rulesMatch <- is.subset(rules@lhs,trxs_trans)

## er zijn meerdere regels, je zou degene met de hoogste lift kunnen kiezen
inspect(rules[rulesMatch[,1]])
inspect(rules[rulesMatch[,1]]@rhs)
```





