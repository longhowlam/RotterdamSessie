---
title: "Avond Sessie 04: Machine learning"
subtitle: "Inleiding R"
author: "Longhow Lam"
output:
  html_notebook:
    theme: sandstone
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
---


---

<br>


```{r, eval=FALSE, include=FALSE}
library(rpart)
library(glmnet)
library(ranger)
library(xgboost)
library(ROCR)
library(titanic)
library(rattle)
library(mlr)
```



# predictive modeling technieken

---

In R kan je veel verschillende predictive modellen fitten. We behandelen alleen een paar in deze sessie. 
Lineare regressie `lm`, logistische regressie met `glm`, decision trees, `rpart` en ensemble van trees met `ranger` en  `xgboost`. Ik zal deze functies apart behandelen maar we zullen later zien met het package `mlr` hoe je op een meer unforme manier meerdere modellen kaan proberen op een data set.


## lineare regressie 
```{r}
mtcars
modelout = lm(  hp ~ wt    , data = mtcars)
modelout2 = lm( hp ~ wt + mpg, data = mtcars) 

modelout
```

Modeling functies in R retourneren vaan objecten met van alles er nog wat in. De functie `lm` levert een object af van de klasse lm.

```{r}
class(modelout)
names(modelout)
modelout$coefficients

summary(modelout)
plot(modelout)
```

### formula objects

```{r}

names(mtcars)

f1 <- hp ~ wt + carb + vs
m1 = lm(f1, data = mtcars)

f2 <- hp ~ carb*wt*vs
m2 = lm(f2, data = mtcars)

f2a <- hp ~ I(carb*wt*vs)
m2a = lm(f2a, data = mtcars)

f3 <- hp ~ carb*wt*vs - carb:wt:vs
m3 = lm(f3, data = mtcars)

f4 = hp ~ .
m4 = lm(f4, data = mtcars)

## vergelijken van verschillende modellen
anova(m1,m3,m2)
```


## splitsen  train test

```{r}

```


## logistic regression



## decision tree
```{r}

titanic_train
tree.out = rpart(Survived ~ Sex + Age, data = titanic_train)
plot(tree.out)
text(tree.out, use.n = TRUE)


fancyRpartPlot(tree.out)

### larger trees with complexity parameter
tree.out = rpart(Survived ~ Sex + Age, data = titanic_train, control = list(cp=0.005))
fancyRpartPlot(tree.out)

```


## random forest met ranger

```{r}


```

## xgboost


## predictie en validatie

Met een test set kan je bepalen hoe goed een model is. Gberuik het model om de test set te scoren en vergelijk de scores met de ware uitkomsten.

### predicties

```{r}

```

### roc curves and hit rates

````{r}

test 
testpr = predict(tree.out, titanic_test)
test$predictie = testpr


rocResultTEST = roc(Target  ~ predictionRANGER, data = test , auc=TRUE, ci =TRUE)
plot(rocResultTEST)


## HITRATES 
RANGER_test = test  %>% mutate(
  Target = ifelse(Target== "Y",1,0)
)

RANGER_test %>% 
  ggplot(aes(predictionRANGER, Target))  +
  geom_smooth() +
  geom_abline(slope = 1,intercept = 0) +
  ggtitle("Young class hit rate on test set") + scale_y_continuous(limits=c(0,1))

ggplot(data = RANGER_test, aes(predictionRANGER, fill = "test")) + geom_density(color='black') +
  ggtitle("Distribution of Young score (Probability that Age < 35)")

````




<br>

# The h2o package

---

H2O is een schaalbaar machine learning platform die je vanuit R kan bedienen, het bevat veel technieken en voor grotere sets waar gewoon R moeite mee heeft kan h2o een uitkomst bieden. H2o heeft een eigen 'executie engine' geschreven in java. Bij het opstarten van h2o vanuit R wordt dan ook een apart h2o process opgestart waar je data vanuit R naar toe moet uploaden.

```{r}
library(h2o)

# initialiseer h20 via R

h2o.init(nthreads=-1, port=54323, startH2O = FALSE)

### upload een R data set naar h2o: iris voorbeeldje
iris.h2o = as.h2o(iris)
titanic.h2o = as.h2o(titanic::titanic_train) 

### Je kan ook direct text files inlezen in h20 met 
h2o.importFile(path="C:\een file.txt", sep=",")

### welke files zijn er in h2o
h2o.ls()
```


Er zijn diverse modellen die je kan trainen, we zullen hier een tweetal laten zien, neural netwerks en random forests

```{r}
## model op titanic

## splits train en test

NNmodel = h2o.deeplearning(
  x = inp,
  y = "BAD",
  training_frame  = HMEQT,
  validation_frame = HMEQV,
  hidden = c(35,35),
  epochs = 250,
  variable_importances = TRUE
)

show(NNmodel)
h2o.varimp(NNmodel)

### Voorspel op validatie set en zet uit in roc curve
HMEQVP = h2o.predict(NNmodel, newdata = HMEQV)
head(HMEQVP)

NEURAL.PERF = as.data.frame(HMEQVP)

plot.roc(HMEQ_VALID$BAD, NEURAL.PERF$p1  , add=T, col="red")


### fit een random forest



```


<br>

# The mlr package

---

Met het `mlr` package kan je makkelijk verschillende modellen trainen en testen op een meer uniforme manier. In R hebben alle machine learning technieken net weer verschillende aanroepen en de uitkomst is vaak ook steeds anders. Met `mlr` kan je dit uniform stroomlijnen. Het maken van een predictive model (welk model dan ook)  bestaat altijd uit een aantal stappen. Deze zijn te beschrijven en uit te voeren in mlr.

We gebruiken de `titanic` data set als test in `mlr` en doorlopen een aantal stappen on een aantal modellen te benchmarken.

* neuraal netwerk,
* gradient boosting,
* random forest
* xgboost
* decision tree,
* logistic regression via glmnet



## specificeren van technieken en hun opties

```{r}
configureMlr(on.par.without.desc = "warn")

n.importance = 30
ptype = "prob"

N_CV_iter = 10

parameters_rf = list(
  num.trees  = 500
)

parameters_rpart = list(
  cp=0.0001
)

parameters_glmnet = list(
  alpha  = 1
)

parameters_NN = list(
  hidden = c(15,15)
)

parameters_xgboost = list(
  nrounds  = 5,
  max.depth = 7
)

```

Maak nu een Lijst van learners die je wilt testen

```{r}
RF_Learner = makeLearner(
  "classif.ranger",
  predict.type = ptype,
  par.vals = parameters_rf
)

xgboost_Learner = makeLearner(
  "classif.xgboost",
  predict.type = ptype,
  par.vals = parameters_xgboost
)

rpart_Learner = makeLearner(
  "classif.rpart",
  predict.type = ptype,
  par.vals = parameters_rpart
)

binomial_Learner = makeLearner(
  "classif.binomial",
  predict.type = ptype
)

glmnet_Learner = makeLearner(
  "classif.cvglmnet", 
  predict.type = ptype,
  par.vals = parameters_glmnet
)

h2ogbm_Learner = makeLearner(
  "classif.h2o.gbm", 
  predict.type = "prob"
)

h2oNN_Learner = makeLearner(
  "classif.h2o.deeplearning",
  predict.type = ptype,
  par.vals = parameters_NN
)


learners = list(
  rpart_Learner,
  RF_Learner,
  binomial_Learner,
  glmnet_Learner,
#  h2ogbm_Learner,
#  h2oNN_Learner,
  xgboost_Learner
)

```


Specificeer de data, de inputs en de target,  de classificatie of regressie task 

Wat wil je modelleren: Kans op level "Y", dan dien je positive = "Y" op te geven. Bij een binaie target met Y en N levels wordt namelijk standaard "N"gebruik (alfabetisch)

```{r}
classify.task = makeClassifTask(id = "RTL_NIEUWSAPP_AGE", data = ABT, target = "Target", positive = "Y")

## Overzicht van de taak en kolom informatie

print(classify.task)
getTaskDescription(classify.task)
summarizeColumns(classify.task)

```

variablen hard uitsluiten 

```{r}

#classify.task = dropFeatures(classify.task, vars.to.drop )

## Weghalen van (bijna) constante variabelen 

## Je kan ook 'bijna' constante variabelen weghalen: perc iets hoger zetten
## not done here
#classify.task = removeConstantFeatures(classify.task, perc = 0)

```

Zeldzame levels van factors samenvoegen. Het is gebruikelijk om zeldzame levels te verwijderen of te mergen

```{r}
#classify.task = mergeSmallFactorLevels (classify.task, min.perc = 0.02,  new.level = ".merged")
#summarizeColumns(classify.task)

```


```{r}
## Feature selection 

#fv = generateFilterValuesData(classify.task,  method = c("information.gain", "chi.squared", "rf.importance"))
fv = generateFilterValuesData(classify.task,  method = c("information.gain", "chi.squared"))


## display en plot importance

importance = fv$data %>% arrange(desc(information.gain))
head(importance, n = n.importance)
plotFilterValues(fv, n.show = 2*n.importance)

 
## no filtering
# summarizeColumns(filtered.task)
# getTaskNFeats(filtered.task)

```


## Sample schema 


uitleg.....

```{r}
#SampleStrageyHO = makeResampleDesc("Holdout", split=0.75)
# SampleStrageyCV = makeResampleDesc("CV", iters = N_CV_iter)
N = dim(ABT)[1]
SampleStrageyHO = makeFixedHoldoutInstance(tidx, testidx, N)
```

## uitvoeren machine learning becnhamrk 

```{r}
br1 = mlr::benchmark(learners, classify.task, SampleStrageyHO, measures = list(mlr::mmce, mlr::auc, mlr::f1))
br2 = mlr::benchmark(learners, filtered.task, SampleStrageyCV, measures = list(mlr::mmce, mlr::auc, mlr::f1))


## Vergelijking machine learning modellen

data.frame(br1) %>% arrange(desc(auc))
plotBMRSummary(br1, measure = mlr::auc)
plotBMRBoxplots(br2, measure = mlr::auc)


#### ROC curves
NModels = length(br1$results$RTL_NIEUWSAPP_AGE)
for(i in 1:NModels)
{
  tmp2  = br1$results$RTL_NIEUWSAPP_AGE[[i]]$pred$data
  rocResultTEST = roc(truth  ~ prob.Y, data = tmp2 )
  if(i==1)
  {
    plot(rocResultTEST, col=i)
  }else{
    plot(rocResultTEST, col=i, add=TRUE)
  }
}

legend( 0.6,0.6, names(br1$results$RTL_NIEUWSAPP_AGE), col=1:NModels,lwd=2)
title("RTL_NIEUWS_APP AGE MODEL")
```

<br>

# Unsupervised learning

---

De bovenstaande code was gericht op predictive modeling, ook wel supervised learning genoemd: met input variabelen een target variable proberen te voorspellen. In deze sectie zullen we een tweetal technieken laten zien waar geen target variabele is, ook wel unsupervised learning genoemd.

## Clustering


```{r}

```


## Market basket analyse